{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29719be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1111, 6)\n",
      "Cleaned shape: (1058, 6)\n",
      "✅ Saved cleaned customers to C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\customers_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process\n",
    "\n",
    "def clean_customers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean the customers dataframe by handling:\n",
    "    - Missing values\n",
    "    - Duplicates\n",
    "    - Typos in categorical fields\n",
    "    - Inconsistent formats\n",
    "    - Mixed date formats\n",
    "    - Non-sequential IDs\n",
    "    - Future dates\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Handle missing values\n",
    "    # -------------------------------   \n",
    "    df[\"FirstName\"] = df[\"FirstName\"].fillna(\"Unknown\")\n",
    "    df[\"LastName\"] = df[\"LastName\"].fillna(\"Unknown\")\n",
    "    df[\"AddressID\"] = df[\"AddressID\"].fillna(0)\n",
    "    df[\"DateOfBirth\"] = pd.to_datetime(df[\"DateOfBirth\"], errors=\"coerce\")\n",
    "    df[\"DateOfBirth\"].fillna(pd.Timestamp(\"1970-01-01\"))\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Remove duplicates\n",
    "    # -------------------------------\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. Fix typos (example: CustomerTypeID mapping)\n",
    "    # -------------------------------\n",
    "    # Suppose CustomerTypeID must map to {1, 2, 3}\n",
    "    valid_types = [1, 2, 3]\n",
    "    df = df[df[\"CustomerTypeID\"].isin(valid_types)]\n",
    "\n",
    "    # Example for country (if customers table had country info)\n",
    "    # valid_countries = [\"United States\"]\n",
    "    # df[\"Country\"] = df[\"Country\"].apply(\n",
    "    #     lambda x: process.extractOne(x, valid_countries)[0]\n",
    "    # )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. Fix inconsistent formats\n",
    "    # -------------------------------\n",
    "    # Ensure AddressID is numeric\n",
    "    df[\"AddressID\"] = pd.to_numeric(df[\"AddressID\"], errors=\"coerce\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5. Standardize date formats\n",
    "    # -------------------------------\n",
    "    df[\"DateOfBirth\"] = pd.to_datetime(df[\"DateOfBirth\"], errors=\"coerce\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 6. Check non-sequential IDs\n",
    "    # -------------------------------\n",
    "    if not df[\"CustomerID\"].is_unique:\n",
    "        df = df.drop_duplicates(subset=[\"CustomerID\"], keep=\"first\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 7. Remove future dates\n",
    "    # -------------------------------\n",
    "    today = pd.Timestamp.today()\n",
    "    df = df[df[\"DateOfBirth\"] <= today]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\raw\\customers.csv\"\n",
    "    output_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\customers_cleaned.csv\"\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    cleaned = clean_customers(df)\n",
    "    print(f\"Cleaned shape: {cleaned.shape}\")\n",
    "\n",
    "    cleaned.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Saved cleaned customers to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb802ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (50000, 8)\n",
      "Cleaned shape: (48042, 8)\n",
      "✅ Saved cleaned transactions to C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\transactions_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process\n",
    "\n",
    "def clean_transactions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean the transactions dataframe by handling:\n",
    "    - Missing values\n",
    "    - Duplicates\n",
    "    - Inconsistent number/text formats\n",
    "    - Mixed date formats\n",
    "    - Non-sequential IDs\n",
    "    - Future dates\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Handle missing values\n",
    "    # -------------------------------\n",
    "    # Amount and IDs must be numeric\n",
    "    df[\"Amount\"] = pd.to_numeric(df[\"Amount\"], errors=\"coerce\")\n",
    "    df[\"AccountOriginID\"] = pd.to_numeric(df[\"AccountOriginID\"], errors=\"coerce\")\n",
    "    df[\"AccountDestinationID\"] = pd.to_numeric(df[\"AccountDestinationID\"], errors=\"coerce\")\n",
    "    df[\"BranchID\"] = pd.to_numeric(df[\"BranchID\"], errors=\"coerce\")\n",
    "    df[\"TransactionTypeID\"] = pd.to_numeric(df[\"TransactionTypeID\"], errors=\"coerce\")\n",
    "\n",
    "    # Fill missing Description\n",
    "    df[\"Description\"] = df[\"Description\"].fillna(\"Unknown\")\n",
    "\n",
    "    # Drop rows with critical missing data (IDs or Amount)\n",
    "    df=df.dropna(subset=[\"TransactionID\", \"AccountOriginID\", \"AccountDestinationID\", \"Amount\"])\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Remove duplicates\n",
    "    # -------------------------------\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. Fix typos (example: TransactionType ID mapping)\n",
    "    # -------------------------------\n",
    "    # Suppose TransactionTypeID must map to {1, 2, 3,4}\n",
    "    valid_types = [1, 2, 3,4]\n",
    "    df = df[df[\"TransactionTypeID\"].isin(valid_types)]\n",
    "    \n",
    "    # Normalize amounts with commas or 'k' notation\n",
    "    def normalize_amount(x):\n",
    "        if isinstance(x, str):\n",
    "            x = x.replace(\",\", \"\").lower()\n",
    "            if \"k\" in x: \n",
    "                x = float(x.replace(\"k\", \"\")) * 1000\n",
    "        return float(x)\n",
    "    \n",
    "    df[\"Amount\"] = df[\"Amount\"].apply(normalize_amount)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. Standardize date formats\n",
    "    # -------------------------------\n",
    "    df[\"TransactionDate\"] = pd.to_datetime(df[\"TransactionDate\"], errors=\"coerce\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5. Check non-sequential IDs\n",
    "    # -------------------------------\n",
    "    if not df[\"TransactionID\"].is_unique:\n",
    "        df = df.drop_duplicates(subset=[\"TransactionID\"], keep=\"first\")\n",
    "    df = df.sort_values(\"TransactionID\").reset_index(drop=True)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 6. Remove future dates\n",
    "    # -------------------------------\n",
    "    today = pd.Timestamp.today()\n",
    "    df = df[df[\"TransactionDate\"] <= today]\n",
    "\n",
    "    # -------------------------------\n",
    "    # 7. Remove future dates\n",
    "    # -------------------------------\n",
    "    today = pd.Timestamp.today()\n",
    "    df = df[df[\"TransactionDate\"] <= today]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\raw\\transactions.csv\"\n",
    "    output_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\transactions_cleaned.csv\"\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    cleaned = clean_transactions(df)\n",
    "    print(f\"Cleaned shape: {cleaned.shape}\")\n",
    "\n",
    "    cleaned.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Saved cleaned transactions to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e44b70c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1667, 6)\n",
      "Cleaned shape: (1635, 6)\n",
      "✅ Saved cleaned accounts to C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\accounts_cleaned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_26136\\739483658.py:59: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[\"OpeningDate\"] = pd.to_datetime(df[\"OpeningDate\"], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process\n",
    "\n",
    "def clean_accounts(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean the accounts dataframe by handling:\n",
    "    - Missing values\n",
    "    - Duplicates\n",
    "    - Typos in categorical fields\n",
    "    - Inconsistent number/text formats\n",
    "    - Mixed date formats\n",
    "    - Non-sequential IDs\n",
    "    - Future dates\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Handle missing values\n",
    "    # -------------------------------\n",
    "    # Numeric fields: Balance\n",
    "    df[\"Balance\"] = pd.to_numeric(df[\"Balance\"], errors=\"coerce\")\n",
    "    #df[\"Balance\"].fillna(df[\"Balance\"].median(), inplace=True)\n",
    "\n",
    "    # Categorical IDs: AccountTypeID, AccountStatusID\n",
    "    df[\"AccountTypeID\"] = pd.to_numeric(df[\"AccountTypeID\"], errors=\"coerce\")\n",
    "    df[\"AccountStatusID\"] = pd.to_numeric(df[\"AccountStatusID\"], errors=\"coerce\")\n",
    "\n",
    "    # Dates\n",
    "    df[\"OpeningDate\"] = pd.to_datetime(df[\"OpeningDate\"], errors=\"coerce\")\n",
    "    df[\"OpeningDate\"]=df['OpeningDate'].fillna(pd.Timestamp(\"2000-01-01\"))\n",
    "    \n",
    "    # Drop rows with critical missing data (IDs or Amount)\n",
    "    df=df.dropna(subset=[\"AccountID\", \"CustomerID\", \"AccountTypeID\", \"AccountStatusID\", \"Balance\"])  # placeholder for missing dates\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Remove duplicates\n",
    "    # -------------------------------\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. Fix typos in categorical fields\n",
    "    # -------------------------------\n",
    "    # Suppose valid AccountTypeIDs = [1,2,3,4,5] and AccountStatusIDs = [1,2,3]\n",
    "    valid_account_types = [1, 2, 3, 4, 5]\n",
    "    valid_statuses = [1, 2, 3]\n",
    "\n",
    "    df = df[df[\"AccountTypeID\"].isin(valid_account_types)]\n",
    "    df = df[df[\"AccountStatusID\"].isin(valid_statuses)]\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. Fix inconsistent number/text formats\n",
    "    # -------------------------------\n",
    "    # Ensure AccountID and CustomerID are numeric\n",
    "    df[\"AccountID\"] = pd.to_numeric(df[\"AccountID\"], errors=\"coerce\")\n",
    "    df[\"CustomerID\"] = pd.to_numeric(df[\"CustomerID\"], errors=\"coerce\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5. Standardize date formats\n",
    "    # -------------------------------\n",
    "    df[\"OpeningDate\"] = pd.to_datetime(df[\"OpeningDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 6. Check non-sequential IDs\n",
    "    # -------------------------------\n",
    "    if not df[\"AccountID\"].is_unique:\n",
    "        df = df.drop_duplicates(subset=[\"AccountID\"], keep=\"first\")\n",
    "\n",
    "    df = df.sort_values(\"AccountID\").reset_index(drop=True)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 7. Remove future dates\n",
    "    # -------------------------------\n",
    "    today = pd.Timestamp.today()\n",
    "    df = df[df[\"OpeningDate\"] <= today]\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\raw\\accounts.csv\"\n",
    "    output_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\accounts_cleaned.csv\"\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    cleaned = clean_accounts(df)\n",
    "    print(f\"Cleaned shape: {cleaned.shape}\")\n",
    "\n",
    "    cleaned.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Saved cleaned accounts to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f43404da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (333, 7)\n",
      "Cleaned shape: (316, 7)\n",
      "✅ Saved cleaned loans to C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\loans_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_loans(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean the loans dataframe by handling:\n",
    "    - Missing values (drop rows)\n",
    "    - Duplicates\n",
    "    - Inconsistent number/text formats\n",
    "    - Mixed date formats\n",
    "    - Non-sequential IDs\n",
    "    - Future dates\n",
    "    - Typos in categorical fields (LoanStatusID)\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Handle missing values\n",
    "    # -------------------------------\n",
    "    # Numeric fields\n",
    "    df[\"PrincipalAmount\"] = pd.to_numeric(df[\"PrincipalAmount\"], errors=\"coerce\")\n",
    "    df[\"InterestRate\"] = pd.to_numeric(df[\"InterestRate\"], errors=\"coerce\")\n",
    "    df[\"LoanID\"] = pd.to_numeric(df[\"LoanID\"], errors=\"coerce\")\n",
    "    df[\"AccountID\"] = pd.to_numeric(df[\"AccountID\"], errors=\"coerce\")\n",
    "    df[\"LoanStatusID\"] = pd.to_numeric(df[\"LoanStatusID\"], errors=\"coerce\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # Drop rows with missing critical fields\n",
    "    df=df.dropna(subset=[\"LoanID\", \"AccountID\", \"LoanStatusID\", \"PrincipalAmount\", \"InterestRate\"])\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Remove duplicates\n",
    "    # -------------------------------\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. Fix typos in categorical fields\n",
    "    # -------------------------------\n",
    "    # Valid LoanStatusIDs = [1, 2, 3]\n",
    "    valid_statuses = [1, 2, 3]\n",
    "    df = df[df[\"LoanStatusID\"].isin(valid_statuses)]\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. Fix inconsistent number/text formats\n",
    "    # -------------------------------\n",
    "    # Already ensured numeric conversion above\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5. Standardize date formats\n",
    "    # -------------------------------\n",
    "    # Dates\n",
    "    df[\"StartDate\"] = pd.to_datetime(df[\"StartDate\"], errors=\"coerce\")\n",
    "    df[\"EstimatedEndDate\"] = pd.to_datetime(df[\"EstimatedEndDate\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop rows with missing critical fields\n",
    "    df=df.dropna(subset=[\"StartDate\", \"EstimatedEndDate\"])\n",
    "\n",
    "    # -------------------------------\n",
    "    # 6. Check non-sequential IDs\n",
    "    # -------------------------------\n",
    "    if not df[\"LoanID\"].is_unique:\n",
    "        df = df.drop_duplicates(subset=[\"LoanID\"], keep=\"first\")\n",
    "    df = df.sort_values(\"LoanID\").reset_index(drop=True)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 7. Remove future dates\n",
    "    # -------------------------------\n",
    "    today = pd.Timestamp.today()\n",
    "    df = df[df[\"StartDate\"] <= today]\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\raw\\loans.csv\"\n",
    "    output_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\loans_cleaned.csv\"\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    cleaned = clean_loans(df)\n",
    "    print(f\"Cleaned shape: {cleaned.shape}\")\n",
    "\n",
    "    cleaned.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Saved cleaned loans to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd51e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1222, 4)\n",
      "Cleaned shape: (1210, 4)\n",
      "✅ Saved cleaned addresses to C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\addresses_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process\n",
    "\n",
    "def clean_addresses(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean the addresses dataframe by handling:\n",
    "    - Missing values (drop rows)\n",
    "    - Duplicates\n",
    "    - Typos in text fields\n",
    "    - Inconsistent text formats\n",
    "    - Non-sequential IDs\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Handle missing values\n",
    "    # -------------------------------\n",
    "    df[\"Street\"]=df[\"Street\"].fillna(\"Unknown\")\n",
    "    df[\"City\"]=df[\"City\"].fillna(\"Unknown\")\n",
    "    df[\"Country\"]=df[\"Country\"].fillna(\"Unknown\")\n",
    "\n",
    "    # Drop rows with missing AddressID\n",
    "    df[\"AddressID\"] = pd.to_numeric(df[\"AddressID\"], errors=\"coerce\")\n",
    "    df=df.dropna(subset=[\"AddressID\"])\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Remove duplicates\n",
    "    # -------------------------------\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. Fix typos in text fields\n",
    "    # -------------------------------\n",
    "    # Example: standardize Country field\n",
    "    valid_countries = [\"United States\"]  # expand if needed\n",
    "    df[\"Country\"] = df[\"Country\"].apply(\n",
    "        lambda x: process.extractOne(str(x), valid_countries)[0]\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. Fix inconsistent text formats\n",
    "    # -------------------------------\n",
    "    df[\"Street\"] = df[\"Street\"].str.title().str.strip()\n",
    "    df[\"City\"] = df[\"City\"].str.title().str.strip()\n",
    "    df[\"Country\"] = df[\"Country\"].str.title().str.strip()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5. Standardize ID format\n",
    "    # -------------------------------\n",
    "    df[\"AddressID\"] = df[\"AddressID\"].astype(int)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 6. Check non-sequential IDs\n",
    "    # -------------------------------\n",
    "    if not df[\"AddressID\"].is_unique:\n",
    "        df = df.drop_duplicates(subset=[\"AddressID\"], keep=\"first\")\n",
    "\n",
    "    df = df.sort_values(\"AddressID\").reset_index(drop=True)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 7. Future dates\n",
    "    # -------------------------------\n",
    "    # Not applicable for Addresses table\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\raw\\addresses.csv\"\n",
    "    output_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\addresses_cleaned.csv\"\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    cleaned = clean_addresses(df)\n",
    "    print(f\"Cleaned shape: {cleaned.shape}\")\n",
    "\n",
    "    cleaned.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Saved cleaned addresses to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d33dcc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (50, 3)\n",
      "Cleaned shape: (50, 3)\n",
      "✅ Saved cleaned branches to C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\branches_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_branches(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean the branches dataframe by handling:\n",
    "    - Missing values (drop rows)\n",
    "    - Duplicates\n",
    "    - Typos in text fields\n",
    "    - Inconsistent number/text formats\n",
    "    - Non-sequential IDs\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Handle missing values\n",
    "    # -------------------------------\n",
    "    df[\"BranchName\"]=df[\"BranchName\"].fillna(\"Unknown\")\n",
    "\n",
    "    # Numeric fields\n",
    "    df[\"BranchID\"] = pd.to_numeric(df[\"BranchID\"], errors=\"coerce\")\n",
    "    df[\"AddressID\"]=pd.to_numeric(df[\"AddressID\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop rows with missing critical fields\n",
    "    df=df.dropna(subset=[\"BranchID\", \"AddressID\"])\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Remove duplicates\n",
    "    # -------------------------------\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. Fix typos in text fields\n",
    "    # -------------------------------\n",
    "    # Example: normalize BranchName by stripping spaces\n",
    "    df[\"BranchName\"] = df[\"BranchName\"].str.strip().str.title()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. Fix inconsistent number/text formats\n",
    "    # -------------------------------\n",
    "    # Already handled above (numeric IDs)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5. Standardize date formats\n",
    "    # -------------------------------\n",
    "    # Not applicable\n",
    "\n",
    "    # -------------------------------\n",
    "    # 6. Check non-sequential IDs\n",
    "    # -------------------------------\n",
    "    if not df[\"BranchID\"].is_unique:\n",
    "        df = df.drop_duplicates(subset=[\"BranchID\"], keep=\"first\")\n",
    "    df = df.sort_values(\"BranchID\").reset_index(drop=True)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 7. Future dates\n",
    "    # -------------------------------\n",
    "    # Not applicable\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\raw\\branches.csv\"\n",
    "    output_file = r\"C:\\Users\\hamza\\OneDrive\\Desktop\\InterviewPrepUSA\\UCSC_Extension\\IntroToMachineLearning\\synthetic-finance-mlops\\data\\processed\\branches_cleaned.csv\"\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    cleaned = clean_branches(df)\n",
    "    print(f\"Cleaned shape: {cleaned.shape}\")\n",
    "\n",
    "    cleaned.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Saved cleaned branches to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
